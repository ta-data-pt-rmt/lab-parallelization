{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization Lab\n",
    "\n",
    "In this lab, you will be leveraging several concepts you have learned to obtain a list of links from a web page and crawl and index the pages referenced by those links - both sequentially and in parallel. Follow the steps below to complete the lab.\n",
    "\n",
    "### Step 1: Use the requests library to retrieve the content from the URL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Data_science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use BeautifulSoup to extract a list of all the unique links on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "soup = BeautifulSoup(response.content)\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use list comprehensions with conditions to clean the link list.\n",
    "\n",
    "There are two types of links, absolute and relative. Absolute links have the full URL and begin with *http* while relative links begin with a forward slash (/) and point to an internal page within the *wikipedia.org* domain. Clean the respective types of URLs as follows.\n",
    "\n",
    "- Absolute Links: Create a list of these and remove any that contain a percentage sign (%).\n",
    "- Relative Links: Create a list of these, add the domain to the link so that you have the full URL, and remove any that contain a percentage sign (%).\n",
    "- Combine the list of absolute and relative links and ensure there are no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute links\n",
    "\n",
    "# Get the request and clean string\n",
    "absol_links = soup.find_all(\"a\", attrs={'class':'external text'})\n",
    "list = [str(link) for link in absol_links]\n",
    "list = [link.replace('<a class=\"external text\" href=', '') for link in list]\n",
    "list = [link.split('\"') for link in list]\n",
    "\n",
    "# Create link list, delete the ones with \"?\"\n",
    "list2 = [(i[1]) for i in list] \n",
    "absol_list = [item for item in list2 if not \"?\" in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative links\n",
    "\n",
    "domain = 'http://wikipedia.org'\n",
    "relat_links = soup.find_all(\"a\",attrs={'class':'mw-redirect'})\n",
    "\n",
    "# Get the request and clean string\n",
    "list = [str(link) for link in relat_links]\n",
    "list = [link.replace('<a class=\"mw-redirect\" href=', '') for link in list]\n",
    "list = [link.split('\"') for link in list]\n",
    "\n",
    "# Create link list, delete the ones with \"?\"\n",
    "list2 = [(domain+i[1]) for i in list] \n",
    "relat_list = [item for item in list2 if not \"?\" in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.worldcat.org/issn/0036-8075',\n",
       " 'http://pubmed.ncbi.nlm.nih.gov/23074866',\n",
       " 'https://api.semanticscholar.org/CorpusID:9743327',\n",
       " 'https://www.oreilly.com/library/view/doing-data-science/9781449363871/ch01.html',\n",
       " 'http://wikipedia.org/wiki/Interdisciplinary',\n",
       " 'http://wikipedia.org/wiki/Data_transformation',\n",
       " 'https://www.bostonglobe.com/business/2015/11/11/behind-scenes-sexiest-job-century/Kc1cvXIu31DfHhVmyRQeIJ/story.html',\n",
       " 'https://hbr.org/2022/07/is-data-scientist-still-the-sexiest-job-of-the-21st-century',\n",
       " 'http://wikipedia.org/wiki/New_York_Times',\n",
       " 'http://www.worldcat.org/oclc/489990740',\n",
       " 'https://doi.org/10.3390%2Fmake1010015',\n",
       " 'https://api.semanticscholar.org/CorpusID:207595944',\n",
       " 'https://medriscoll.com/post/4740157098/the-three-sexy-skills-of-data-geeks',\n",
       " 'http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/',\n",
       " 'https://flowingdata.com/2009/06/04/rise-of-the-data-scientist/',\n",
       " 'http://archive.nyu.edu/handle/2451/31553',\n",
       " 'http://wikipedia.org/wiki/Phenomena',\n",
       " 'https://www.springer.com/book/9784431702085',\n",
       " 'http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf',\n",
       " 'https://web.archive.org/web/20190620184935/https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/',\n",
       " 'https://magazine.amstat.org/blog/2016/06/01/datascience-2/',\n",
       " 'http://wikipedia.org/wiki/Data_visualization',\n",
       " 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century',\n",
       " 'http://wikipedia.org/wiki/Information_visualization',\n",
       " 'http://wikipedia.org/wiki/Committee_on_Data_for_Science_and_Technology',\n",
       " 'http://wikipedia.org/wiki/Data_(computing)',\n",
       " 'http://wikipedia.org/wiki/OCLC_(identifier)',\n",
       " 'https://statmodeling.stat.columbia.edu/2013/11/14/statistics-least-important-part-data-science/',\n",
       " 'http://wikipedia.org/wiki/ISBN_(identifier)',\n",
       " 'https://www.forbes.com/sites/peterpham/2015/08/28/the-impacts-of-big-data-that-you-may-not-have-heard-of/',\n",
       " 'http://wikipedia.org/wiki/Doi_(identifier)',\n",
       " 'https://www.forbes.com/sites/gilpress/2013/08/19/data-science-whats-the-half-life-of-a-buzzword/',\n",
       " 'http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext',\n",
       " 'https://web.archive.org/web/20140102194117/http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/',\n",
       " 'http://www.worldcat.org/issn/0017-8012',\n",
       " 'https://www.nsf.gov/pubs/2005/nsb0540/',\n",
       " 'http://wikipedia.org/wiki/S2CID_(identifier)',\n",
       " 'http://www.datascienceassn.org/about-data-science',\n",
       " 'http://wikipedia.org/wiki/Data_loading',\n",
       " 'https://towardsdatascience.com/how-data-science-will-impact-future-of-businesses-7f11f5699c4d',\n",
       " 'http://wikipedia.org/wiki/PMID_(identifier)',\n",
       " 'https://doi.org/10.1145%2F3076253',\n",
       " 'https://www.stat.purdue.edu/~wsc/',\n",
       " 'https://www.nytimes.com/2013/04/14/education/edlife/universities-offer-courses-in-a-hot-new-field-data-science.html',\n",
       " 'https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/',\n",
       " 'https://doi.org/10.1007%2F978-4-431-65950-1_3',\n",
       " 'https://doi.org/10.1126%2Fscience.1170411',\n",
       " 'https://web.archive.org/web/20141109113411/http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext',\n",
       " 'https://web.archive.org/web/20200810114002/http://www.datascienceassn.org/about-data-science',\n",
       " 'https://api.semanticscholar.org/CorpusID:6107147',\n",
       " 'https://www.statisticsviews.com/article/nate-silver-what-i-need-from-statisticians/',\n",
       " 'http://www2.isye.gatech.edu/~jeffwu/presentations/datascience.pdf',\n",
       " 'http://www.worldcat.org/issn/0360-0300',\n",
       " 'http://wikipedia.org/wiki/Complex_systems',\n",
       " 'https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century/',\n",
       " 'http://wikipedia.org/wiki/Boston_Globe',\n",
       " 'https://benfry.com/phd/dissertation/2.html',\n",
       " 'https://www2.isye.gatech.edu/~jeffwu/publications/fazhan.pdf',\n",
       " 'http://priceonomics.com/whats-the-difference-between-data-science-and/',\n",
       " 'https://doi.org/10.3390%2Fbdcc2020014',\n",
       " 'https://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/',\n",
       " 'https://doi.org/10.1145%2F2500499',\n",
       " 'http://wikipedia.org/wiki/ISSN_(identifier)',\n",
       " 'http://pubmed.ncbi.nlm.nih.gov/19265007']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to set to erase repeated and then again into list\n",
    "final_set = set(absol_list+relat_list)\n",
    "final_list = [item for item in final_set]\n",
    "final_list2 = []\n",
    "\n",
    "# Adding http where is missing\n",
    "for item in final_list:\n",
    "    if item[0]==\"/\":\n",
    "        item = 'http:'+ item\n",
    "        final_list2.append(item)\n",
    "    else:\n",
    "        final_list2.append(item)\n",
    "\n",
    "final_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the os library to create a folder called *wikipedia* and make that the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: C:\\Users\\fcavanagh\\Desktop\\Ironhack\\W10\\Day3\\lab-parallelization\\your-code\\wikipedia\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "#     os.mkdir('wikipedia') \n",
    "os.chdir('wikipedia')\n",
    "\n",
    "print(\"New working directory: {0}\".format(os.getcwd()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Write a function called index_page that accepts a link and does the following.\n",
    "\n",
    "- Tries to request the content of the page referenced by that link.\n",
    "- Slugifies the filename using the `slugify` function from the [python-slugify](https://pypi.org/project/python-slugify/) library and adds a .html file extension.\n",
    "    - If you don't already have the python-slugify library installed, you can pip install it as follows: `$ pip3 install python-slugify`.\n",
    "    - To import the slugify function, you would do the following: `from slugify import slugify`.\n",
    "    - You can then slugify a link as follows `slugify(link)`.\n",
    "- Creates a file in the wikipedia folder using the slugified filename and writes the contents of the page to the file.\n",
    "- If an exception occurs during the process above, just `pass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slugify import slugify\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def index_page(link):\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "        file_name = slugify(link)+'.html'\n",
    "        fp = open(file_name, 'w')\n",
    "        fp.write(str(soup))\n",
    "        fp.close()\n",
    "        print('Link: ', link, 'done..')\n",
    "    except:\n",
    "#         print('This link: ', link, 'failed...')\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Sequentially loop through the list of links, running the index_page function each time.\n",
    "\n",
    "Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: C:\\Users\\fcavanagh\\Desktop\\Ironhack\\W10\\Day3\\lab-parallelization\\your-code\\wikipedia\n",
      "Link:  http://pubmed.ncbi.nlm.nih.gov/23074866 done..\n",
      "Link:  https://api.semanticscholar.org/CorpusID:9743327 done..\n",
      "Link:  https://www.oreilly.com/library/view/doing-data-science/9781449363871/ch01.html done..\n",
      "Link:  https://hbr.org/2022/07/is-data-scientist-still-the-sexiest-job-of-the-21st-century done..\n",
      "Link:  https://api.semanticscholar.org/CorpusID:207595944 done..\n",
      "Link:  https://medriscoll.com/post/4740157098/the-three-sexy-skills-of-data-geeks done..\n",
      "Link:  http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/ done..\n",
      "Link:  https://www.springer.com/book/9784431702085 done..\n",
      "Link:  http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf done..\n",
      "Link:  https://web.archive.org/web/20190620184935/https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/ done..\n",
      "Link:  https://magazine.amstat.org/blog/2016/06/01/datascience-2/ done..\n",
      "Link:  https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century done..\n",
      "Link:  https://statmodeling.stat.columbia.edu/2013/11/14/statistics-least-important-part-data-science/ done..\n",
      "Link:  https://www.forbes.com/sites/peterpham/2015/08/28/the-impacts-of-big-data-that-you-may-not-have-heard-of/ done..\n",
      "Link:  https://www.forbes.com/sites/gilpress/2013/08/19/data-science-whats-the-half-life-of-a-buzzword/ done..\n",
      "Link:  http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext done..\n",
      "Link:  https://doi.org/10.1145%2F3076253 done..\n",
      "Link:  https://www.stat.purdue.edu/~wsc/ done..\n",
      "Link:  https://www.nytimes.com/2013/04/14/education/edlife/universities-offer-courses-in-a-hot-new-field-data-science.html done..\n",
      "Link:  https://magazine.amstat.org/blog/2015/10/01/asa-statement-on-the-role-of-statistics-in-data-science/ done..\n",
      "Link:  https://doi.org/10.1007%2F978-4-431-65950-1_3 done..\n",
      "Link:  https://doi.org/10.1126%2Fscience.1170411 done..\n",
      "Link:  https://api.semanticscholar.org/CorpusID:6107147 done..\n",
      "Link:  https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century/ done..\n",
      "Link:  http://priceonomics.com/whats-the-difference-between-data-science-and/ done..\n",
      "Link:  https://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/ done..\n",
      "Link:  https://doi.org/10.1145%2F2500499 done..\n",
      "Link:  http://pubmed.ncbi.nlm.nih.gov/19265007 done..\n",
      "CPU times: total: 9.48 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# os.chdir('wikipedia')\n",
    "print(\"New working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "for link in final_list2:\n",
    "    index_page(link)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Perform the page indexing in parallel and note the difference in performance.\n",
    "\n",
    "Remember to include `%%time` at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: C:\\Users\\fcavanagh\\Desktop\\Ironhack\\W10\\Day3\\lab-parallelization\\your-code\\wikipedia\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"New working directory: {0}\".format(os.getcwd()))\n",
    "                                \n",
    "pool = multiprocessing.Pool(2) \n",
    "pool.map(index_page, [link for link in final_list2])\n",
    "pool.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
